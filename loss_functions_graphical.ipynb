{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# comparing loss functions\n",
    "## a graphical analysis\n",
    "> Sammer, Matthias & Leitner, Paul\n",
    "\n",
    "### Definition, explanation\n",
    "*A loss function is used to optimize the parameter values in a neural network model. \n",
    "Loss functions map a set of parameter values for the network onto a scalar value \n",
    "that indicates how well those parameter accomplish the task the network is intended to do.* \n",
    "\n",
    "Here we will graphically examine a few of the most common loss functions in more detail, \n",
    "in order to gain a more intuitive understanding of the underlying principles in Python\n",
    "\n",
    "### Preparation, packages, data generation\n",
    "\n",
    "since data wrangling is not the exact scope of this investigation, we quickly generate some data from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# generate a large amount of data, unscaled - 20% noise in order to challenge the model\n",
    "X, y = make_regression(n_samples=10000,\n",
    "                       n_features=10,\n",
    "                       noise=.2,\n",
    "                       random_state=1)\n",
    "\n",
    "# this data is of course unscaled --> preprocess the data\n",
    "# usually this would include imputation, EDA, encoding - out of scope here\n",
    "pipe_x = Pipeline(steps=[('scaling', StandardScaler())])\n",
    "pipe_y = Pipeline(steps=[('scaling', StandardScaler())])\n",
    "\n",
    "X_processed = pipe_x.fit_transform(X)\n",
    "y_processed = pipe_y.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X_processed, y_processed, \n",
    "                                                    random_state=1,\n",
    "                                                    test_size=.1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### model generation\n",
    "\n",
    "we quickly generate a sequential NN - as a simple demonstration for graphing the loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import he_uniform\n",
    "\n",
    "\n",
    "# simple sequential model, dense layer, relu activation\n",
    "sequential_model = Sequential()\n",
    "\n",
    "bias_initializer = he_uniform(seed=42)\n",
    "sequential_model.add(Dense(25, \n",
    "                           input_dim=10, \n",
    "                           activation='relu',\n",
    "                           kernel_initializer=bias_initializer))\n",
    "sequential_model.add(Dense(1, \n",
    "                           activation='linear'))\n",
    "\n",
    "# using a simple gradient descent optimizer\n",
    "opt = SGD(lr=0.01, \n",
    "          momentum=0.9)\n",
    "\n",
    "sequential_model.compile(loss='mean_squared_error', \n",
    "                         optimizer=opt)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "> now that we initialized the model, we train it with history and graph the loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Train MSE: 1.0268522585445478e-06, Test MSE: 1.0213509876848548e-06 \n",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-665ef9df8115>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# plot loss over the trainingh epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss / Mean Squared Error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# train the model on our test data in 100 epochs\n",
    "loss_history = sequential_model.fit(train_X, train_y, \n",
    "                                    validation_data=(test_X, test_y), \n",
    "                                    epochs=100, \n",
    "                                    verbose=0)\n",
    "\n",
    "# get the final train and test MSE of the model\n",
    "train_mse = sequential_model.evaluate(train_X, train_y, \n",
    "                                      verbose=0)\n",
    "\n",
    "test_mse = sequential_model.evaluate(test_X, test_y, \n",
    "                                     verbose=0)\n",
    "\n",
    "print(f'Train MSE: {train_mse}, Test MSE: {test_mse} \\n')\n",
    "\n",
    "# plot loss over the trainingh epochs\n",
    "plt.title('Loss / Mean Squared Error')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}